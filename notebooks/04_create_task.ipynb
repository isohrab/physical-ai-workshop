{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4a1bb9d",
   "metadata": {},
   "source": [
    "# Creating a Custom Robotics Task: Pick Pen Tutorial\n",
    "\n",
    "In this tutorial, you will learn how to create a complete robotics task from scratch. We'll build a \"Pick Pen\" task where a robot needs to pick up a mechanical pencil and place it on a plate in a kitchen environment.\n",
    "\n",
    "## Overview\n",
    "\n",
    "By the end of this tutorial, you will have created:\n",
    "\n",
    "- Custom observation functions for detecting task completion\n",
    "- Custom termination conditions\n",
    "- Complete environment configuration\n",
    "- Environment registration for training and data generation\n",
    "\n",
    "## Task Description\n",
    "\n",
    "The Pick Pen task involves three main subtasks:\n",
    "\n",
    "1. **Pick the pen**: Robot approaches and grasps the mechanical pencil\n",
    "2. **Place on plate**: Robot moves the pen to the plate and releases it\n",
    "3. **Return to rest**: Robot returns to its rest position\n",
    "\n",
    "## Step 1: Creating Observation Functions\n",
    "\n",
    "First, we'll create functions to observe task progress. These functions help us determine when each subtask is completed.\n",
    "\n",
    "### Exercise 1.1: Complete the Pen Grasping Detection\n",
    "\n",
    "Navigate to `~/workspace/leisaac/source/leisaac/leisaac/tasks/pick_pen/tasks/pick_pen/mdp/observations.py` and complete the `pen_grasped` function:\n",
    "\n",
    "```python\n",
    "def pen_grasped(\n",
    "    env: ManagerBasedRLEnv,\n",
    "    robot_cfg: SceneEntityCfg = SceneEntityCfg(\"robot\"),\n",
    "    ee_frame_cfg: SceneEntityCfg = SceneEntityCfg(\"ee_frame\"),\n",
    "    object_cfg: SceneEntityCfg = SceneEntityCfg(\"MechanicalPencil\"),\n",
    "    diff_threshold: float = 0.01,\n",
    "    grasp_threshold: float = 0.40,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Check if an object(Pen) is grasped by the specified robot.\"\"\"\n",
    "```\n",
    "\n",
    "**Your Task**: Complete the logic to determine if the pen is grasped by:\n",
    "\n",
    "1. Calculate the distance between the end effector and the pen using `torch.linalg.vector_norm()` with `object_pos - end_effector_pos` and set `dim=1`\n",
    "2. Check if pen is grasped by combining two conditions using `torch.logical_and()`:\n",
    "   - Distance is less than `diff_threshold`\n",
    "   - Gripper is closed: `robot.data.joint_pos[:, -1] < grasp_threshold`\n",
    "\n",
    "### Exercise 1.2: Complete the Pen Placement Detection\n",
    "\n",
    "Still in `observations.py`, complete the `put_pen_to_plate` function:\n",
    "\n",
    "```python\n",
    "def put_pen_to_plate(\n",
    "    env: ManagerBasedRLEnv,\n",
    "    robot_cfg: SceneEntityCfg = SceneEntityCfg(\"robot\"),\n",
    "    ee_frame_cfg: SceneEntityCfg = SceneEntityCfg(\"ee_frame\"),\n",
    "    object_cfg: SceneEntityCfg = SceneEntityCfg(\"MechanicalPencil\"),\n",
    "    plate_cfg: SceneEntityCfg = SceneEntityCfg(\"Plate\"),\n",
    "    x_range: tuple[float, float] = (-0.10, 0.10),\n",
    "    y_range: tuple[float, float] = (-0.10, 0.10),\n",
    "    diff_threshold: float = 0.05,\n",
    "    grasp_threshold: float = 0.60,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Check if an object(pen) is placed on the specified plate.\"\"\"\n",
    "```\n",
    "\n",
    "**Your Task**: Complete the logic to determine if the pen is placed on the plate by:\n",
    "\n",
    "1. Check if pen is within plate X boundaries using `torch.logical_and()` with:\n",
    "   - `pen_x < plate_x + x_range[1]`\n",
    "   - `pen_x > plate_x + x_range[0]`\n",
    "2. Check if pen is within plate Y boundaries using `torch.logical_and()` with:\n",
    "   - `pen_y < plate_y + y_range[1]`\n",
    "   - `pen_y > plate_y + y_range[0]`\n",
    "3. Check if gripper is open: `robot.data.joint_pos[:, -1] > grasp_threshold`\n",
    "4. Combine pen placement condition with end effector proximity using `torch.logical_and(pen_in_plate, ee_near_to_pen)`\n",
    "5. Finally combine with gripper open condition using `torch.logical_and(placed, gripper_open)`\n",
    "\n",
    "## Step 2: Creating Termination Conditions\n",
    "\n",
    "Termination functions determine when an episode should end, either due to success or failure.\n",
    "\n",
    "### Exercise 2.1: Complete the Task Completion Check\n",
    "\n",
    "Navigate to `~/workspace/leisaac/source/leisaac/leisaac/tasks/pick_pen/tasks/pick_pen/mdp/terminations.py` and complete the `task_done` function:\n",
    "\n",
    "```python\n",
    "def task_done(\n",
    "    env: ManagerBasedRLEnv,\n",
    "    pens_cfg: List[SceneEntityCfg],\n",
    "    plate_cfg: SceneEntityCfg,\n",
    "    x_range: tuple[float, float] = (-0.10, 0.10),\n",
    "    y_range: tuple[float, float] = (-0.10, 0.10),\n",
    "    height_range: tuple[float, float] = (-0.07, 0.07),\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Determine if the pen picking task is complete.\"\"\"\n",
    "```\n",
    "\n",
    "**Your Task**: Complete the logic that checks if:\n",
    "\n",
    "1. Check if pen is within X-range relative to plate using `torch.logical_and()` with:\n",
    "   - `pen_x < plate_x + x_range[1]`\n",
    "   - `pen_x > plate_x + x_range[0]`\n",
    "2. Check if pen is within Y-range relative to plate using `torch.logical_and()` with:\n",
    "   - `pen_y < plate_y + y_range[1]`\n",
    "   - `pen_y > plate_y + y_range[0]`\n",
    "3. Check if pen is within height range relative to plate using `torch.logical_and()` with:\n",
    "   - `pen_height < plate_height + height_range[1]`\n",
    "   - `pen_height > plate_height + height_range[0]`\n",
    "4. Check if robot is at rest pose using `torch.logical_and()` with:\n",
    "   - `is_so101_at_rest_pose(joint_pos, joint_names)`\n",
    "\n",
    "## Step 3: Environment Configuration\n",
    "\n",
    "Now we'll set up the complete environment configuration that brings everything together.\n",
    "\n",
    "### Exercise 3.1: Complete the Subtask Observation Configuration\n",
    "\n",
    "Navigate to `~/workspace/leisaac/source/leisaac/leisaac/tasks/pick_pen/tasks/pick_pen/pick_pen_env_cfg.py` and find the `SubtaskCfg` class within `ObservationsCfg`:\n",
    "\n",
    "```python\n",
    "@configclass\n",
    "class SubtaskCfg(ObsGroup):\n",
    "    \"\"\"Observations for subtask group.\"\"\"\n",
    "\n",
    "    # TODO: Add pen grasped observation term\n",
    "    pick_pen = None  # YOUR CODE HERE\n",
    "\n",
    "    # TODO: Add pen placement observation term\n",
    "    put_pen_to_plate = None  # YOUR CODE HERE\n",
    "```\n",
    "\n",
    "**Your Task**: Complete the subtask observation terms by:\n",
    "\n",
    "1. Create `pick_pen` observation using `ObsTerm()` with:\n",
    "   - `func=mdp.pen_grasped` (the function you implemented in Step 1)\n",
    "   - `params={\"object_cfg\": SceneEntityCfg(\"MechanicalPencil\")}`\n",
    "2. Create `put_pen_to_plate` observation using `ObsTerm()` with:\n",
    "   - `func=mdp.put_pen_to_plate` (the function you implemented in Step 1)\n",
    "   - `params={\"object_cfg\": SceneEntityCfg(\"MechanicalPencil\"), \"plate_cfg\": SceneEntityCfg(\"Plate\")}`\n",
    "\n",
    "### Exercise 3.2: Complete the Termination Configuration\n",
    "\n",
    "In the same file, find the `TerminationsCfg` class:\n",
    "\n",
    "```python\n",
    "@configclass\n",
    "class TerminationsCfg:\n",
    "    \"\"\"Configuration for the termination\"\"\"\n",
    "\n",
    "    time_out = DoneTerm(func=mdp.time_out, time_out=True)\n",
    "\n",
    "    # TODO: Add success termination condition using task_done function\n",
    "    success = None  # YOUR CODE HERE\n",
    "```\n",
    "\n",
    "**Your Task**: Configure the success termination condition by:\n",
    "\n",
    "1. Create `success` termination using `DoneTerm()` with:\n",
    "   - `func=mdp.task_done` (the function you implemented in Step 2)\n",
    "   - `params={\"pens_cfg\": [SceneEntityCfg(\"MechanicalPencil\")], \"plate_cfg\": SceneEntityCfg(\"Plate\")}`\n",
    "\n",
    "## Step 4: Mimic Environment for Data Generation\n",
    "\n",
    "The mimic environment is used for generating training data by recording human demonstrations. This environment extends your base environment with additional capabilities for collecting high-quality training data through automated subtask decomposition and trajectory recording.\n",
    "\n",
    "Navigate to `~/workspace/leisaac/source/leisaac/leisaac/tasks/pick_pen/tasks/pick_pen/pick_pen_mimic_env_cfg.py` and examine the subtask configurations. This file contains the complete configuration for data generation - no modifications are needed as it demonstrates how subtasks are automatically broken down and recorded for training.\n",
    "\n",
    "The mimic environment automatically:\n",
    "\n",
    "- Decomposes complex tasks into subtasks (pick_pen → put_pen_to_plate → rest_robot)\n",
    "- Records demonstration trajectories with proper segmentation\n",
    "- Applies domain randomization and noise for robust data collection\n",
    "- Manages task transitions and interpolation between subtask segments\n",
    "\n",
    "## Step 5: Environment Registration\n",
    "\n",
    "Finally, we need to register our environments so they can be used for training and data collection.\n",
    "\n",
    "### Exercise 5.1: Complete Environment Registration\n",
    "\n",
    "Navigate to `~/workspace/leisaac/source/leisaac/leisaac/tasks/pick_pen/tasks/pick_pen/__init__.py`:\n",
    "\n",
    "```python\n",
    "import gymnasium as gym\n",
    "\n",
    "gym.register(\n",
    "    # TODO: Set the environment ID for the standard PickPen environment\n",
    "    id=None,  # YOUR CODE HERE\n",
    "    entry_point=\"isaaclab.envs:ManagerBasedRLEnv\",\n",
    "    disable_env_checker=True,\n",
    "    kwargs={\n",
    "        \"env_cfg_entry_point\": f\"{__name__}.pick_pen_env_cfg:PickPenEnvCfg\",\n",
    "    },\n",
    ")\n",
    "\n",
    "gym.register(\n",
    "    # TODO: Set the environment ID for the mimic environment\n",
    "    id=None,  # YOUR CODE HERE\n",
    "    entry_point=f\"leisaac.enhance.envs:ManagerBasedRLLeIsaacMimicEnv\",\n",
    "    disable_env_checker=True,\n",
    "    kwargs={\n",
    "        \"env_cfg_entry_point\": f\"{__name__}.pick_pen_mimic_env_cfg:PickPenMimicEnvCfg\",\n",
    "    },\n",
    ")\n",
    "```\n",
    "\n",
    "**Your Task**: Complete the gym environment registration by:\n",
    "\n",
    "1. Set the standard environment ID to: `\"LeIsaac-SO101-PickPen-v0\"`\n",
    "2. Set the mimic environment ID to: `\"LeIsaac-SO101-PickPen-Mimic-v0\"`\n",
    "\n",
    "These environment IDs follow the gymnasium naming convention and will be used throughout the training pipeline to identify your custom task.\n",
    "\n",
    "## Step 6: Creating Scene Configuration\n",
    "\n",
    "The final step is to create the scene configuration that defines our kitchen environment with the pen object. This configuration tells the system where to find the USD scene file and how to spawn it.\n",
    "\n",
    "### Exercise 6.1: Complete the Scene Configuration\n",
    "\n",
    "Navigate to `workspace/leisaac/source/leisaac/leisaac/assets/scenes/kitchen.py` and add the kitchen with pen scene configuration:\n",
    "\n",
    "```python\n",
    "# TODO: Add the USD path for the kitchen with pen scene\n",
    "KITCHEN_WITH_PEN_USD_PATH = None  # YOUR CODE HERE\n",
    "\n",
    "# TODO: Create the asset configuration for the kitchen with pen scene\n",
    "KITCHEN_WITH_PEN_CFG = None  # YOUR CODE HERE\n",
    "```\n",
    "\n",
    "Congratulations! You've successfully created a complete robotics task from scratch with all necessary components including observation functions, termination conditions, environment configurations, and scene setup.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd114ce",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
