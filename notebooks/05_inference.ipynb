{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc43a831",
   "metadata": {},
   "source": [
    "# Model Inference and Robot Evaluation\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this final tutorial, we will integrate all components and run inference with the fine-tuned LeRobot model. You will observe the robotic arm performing the pick-and-place task using the trained policy in the Isaac Sim environment.\n",
    "\n",
    "## Step 1: Download the Fine-tuned Model\n",
    "\n",
    "### Obtain Download Link\n",
    "\n",
    "1. Navigate to the workshop Teams channel\n",
    "2. Locate the fine-tuned model download link provided by the instructors\n",
    "\n",
    "### Download and Extract Model\n",
    "\n",
    "1. Open a terminal in your workspace\n",
    "2. Execute the download script with the provided link:\n",
    "\n",
    "   ```bash\n",
    "   bash ./download_model.sh \"<download_link>\"\n",
    "   ```\n",
    "\n",
    "   **Note:** Ensure the URL is enclosed in quotation marks.\n",
    "\n",
    "3. The script will automatically download and extract the model to `/workspace/finetuned_model`\n",
    "\n",
    "## Step 2: Start the Inference Service\n",
    "\n",
    "### Activate GR00T Environment\n",
    "\n",
    "1. Open a terminal window\n",
    "2. Navigate to the gr00t directory:\n",
    "   ```bash\n",
    "   cd workspace/gr00t\n",
    "   ```\n",
    "3. Activate the gr00t environment by `conda activate gr00t`\n",
    "\n",
    "### Launch Inference Server\n",
    "\n",
    "Execute the following command to start the inference service:\n",
    "\n",
    "```bash\n",
    "python scripts/inference_service.py \\\n",
    "    --model-path ../finetuned_model \\\n",
    "    --server \\\n",
    "    --embodiment_tag new_embodiment \\\n",
    "    --data-config so100_dualcam\n",
    "```\n",
    "\n",
    "This command will:\n",
    "\n",
    "- Load the fine-tuned model from the specified path\n",
    "- Start the inference server on the default port (5555)\n",
    "- Configure the system for the new embodiment setup\n",
    "- Use the dual-camera data configuration\n",
    "\n",
    "## Step 3: Execute Policy Inference\n",
    "\n",
    "### Prepare Evaluation Environment\n",
    "\n",
    "1. Open a **new terminal window** (keep the inference server running)\n",
    "2. Navigate to the LeIsaac directory:\n",
    "   ```bash\n",
    "   cd ~/workspace/leisaac\n",
    "   ```\n",
    "3. Activate the leisaac environment by `conda activate leisaac`\n",
    "\n",
    "### Run Policy Evaluation\n",
    "\n",
    "Execute the policy inference script with the following parameters:\n",
    "\n",
    "```bash\n",
    "python scripts/evaluation/policy_inference.py \\\n",
    "    --task=LeIsaac-SO101-PickPen-v0 \\\n",
    "    --eval_rounds=10 \\\n",
    "    --policy_type=gr00tn1.5 \\\n",
    "    --policy_host=localhost \\\n",
    "    --policy_port=5555 \\\n",
    "    --policy_timeout_ms=5000 \\\n",
    "    --policy_action_horizon=16 \\\n",
    "    --policy_language_instruction=\"Pick up the pen and place it on the plate\" \\\n",
    "    --device=cuda \\\n",
    "    --enable_cameras\n",
    "```\n",
    "\n",
    "### Parameter Explanation\n",
    "\n",
    "- `--task`: Specifies the LeIsaac pick pen task environment\n",
    "- `--eval_rounds`: Number of evaluation attempts (10 rounds)\n",
    "- `--policy_type`: GR00T model version 1.5\n",
    "- `--policy_host/port`: Connection details for the inference server\n",
    "- `--policy_timeout_ms`: Maximum wait time for policy response\n",
    "- `--policy_action_horizon`: Number of future actions to predict\n",
    "- `--policy_language_instruction`: Natural language task description\n",
    "- `--device`: GPU acceleration using CUDA\n",
    "- `--enable_cameras`: Activate camera inputs for the policy\n",
    "\n",
    "### Different Views\n",
    "\n",
    "Try different Camera views when Robot is working.\n",
    "Select the Camera Icon on the scene and change it from perspective to camera/wirst or camera/top view\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002c9a21",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
